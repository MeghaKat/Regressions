# Regressions

## Objective
To investigating the classification performance of linear and logistic regression.
To achieve that,Batch Gradient Descent optimization algorithm for a linear regression classifier and logistic regression classifer are implemented. 
The performance of the algorithm is compared against a state-of-the-art optimization technique, ADAM using
Stochastic Gradient Descent. 
For both linear and logistic regression, implementations are done in Numpy. For comparison with ADAM, Tensorflow implementation is used.
For TensorFlow APIs for useful utility functions, visit : https://www.tensorflow.org/api_docs/python/.

## RESULTS
## LINEAR REGRESSION
### Tuning the Learning Rate
